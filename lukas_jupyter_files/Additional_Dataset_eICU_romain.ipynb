{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd69700",
   "metadata": {},
   "source": [
    "# IMPORTS AND PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c763e32a-fd91-45aa-b5f8-0ae856ede83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7f4f05-d230-4d2a-b725-366534c1bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "DATA_PATH = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\eicu-2.0\\eicu_crd\"\n",
    "OUTPUT_PATH = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\eicu-2.0\\processed\"\n",
    "\n",
    "DIAGNOSIS_DATA_PATH = \"diagnosis.csv.gz\"\n",
    "VITALS_DATA_PATH = \"vitalPeriodic.csv.gz\"\n",
    "PATIENT_DATA_PATH = \"patient.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2da5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "SCENARIO = \"core\"  # core, slim, ultra_minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609dd02",
   "metadata": {},
   "source": [
    "# INSPECT TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e4a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis Headers: ['diagnosisid', 'patientunitstayid', 'activeupondischarge', 'diagnosisoffset', 'diagnosisstring', 'icd9code', 'diagnosispriority']\n",
      "Diagnosis Shape: 7\n",
      "Vitals Headers: ['vitalperiodicid', 'patientunitstayid', 'observationoffset', 'temperature', 'sao2', 'heartrate', 'respiration', 'cvp', 'etco2', 'systemicsystolic', 'systemicdiastolic', 'systemicmean', 'pasystolic', 'padiastolic', 'pamean', 'st1', 'st2', 'st3', 'icp']\n",
      "Vitals Shape: 19\n",
      "Patient Headers: ['patientunitstayid', 'patienthealthsystemstayid', 'gender', 'age', 'ethnicity', 'hospitalid', 'wardid', 'apacheadmissiondx', 'admissionheight', 'hospitaladmittime24', 'hospitaladmitoffset', 'hospitaladmitsource', 'hospitaldischargeyear', 'hospitaldischargetime24', 'hospitaldischargeoffset', 'hospitaldischargelocation', 'hospitaldischargestatus', 'unittype', 'unitadmittime24', 'unitadmitsource', 'unitvisitnumber', 'unitstaytype', 'admissionweight', 'dischargeweight', 'unitdischargetime24', 'unitdischargeoffset', 'unitdischargelocation', 'unitdischargestatus', 'uniquepid']\n",
      "Patient Shape: 29\n"
     ]
    }
   ],
   "source": [
    "# Load headers of each CSV and files the columns names and shapes\n",
    "def load_csv_headers(data_path, filename):\n",
    "    filepath = os.path.join(data_path, filename)\n",
    "    df = pd.read_csv(filepath, nrows=0)\n",
    "    return df.columns.tolist(), df.shape[1]\n",
    "\n",
    "# Load the headers for each CSV file\n",
    "diagnosis_headers, diagnosis_shape = load_csv_headers(DATA_PATH, DIAGNOSIS_DATA_PATH)\n",
    "vitals_headers, vitals_shape = load_csv_headers(DATA_PATH, VITALS_DATA_PATH)\n",
    "patient_headers, patient_shape = load_csv_headers(DATA_PATH, PATIENT_DATA_PATH)\n",
    "\n",
    "# Print the headers and shapes\n",
    "print(\"Diagnosis Headers:\", diagnosis_headers)\n",
    "print(\"Diagnosis Shape:\", diagnosis_shape)\n",
    "print(\"Vitals Headers:\", vitals_headers)\n",
    "print(\"Vitals Shape:\", vitals_shape)\n",
    "print(\"Patient Headers:\", patient_headers)\n",
    "print(\"Patient Shape:\", patient_shape)\n",
    "\n",
    "# Diagnosis Headers: ['diagnosisid', 'patientunitstayid', 'activeupondischarge', 'diagnosisoffset', 'diagnosisstring', 'icd9code', 'diagnosispriority']\n",
    "# Diagnosis Shape: 7\n",
    "# Vitals Headers: ['vitalperiodicid', 'patientunitstayid', 'observationoffset', 'temperature', 'sao2', 'heartrate', 'respiration', 'cvp', 'etco2', 'systemicsystolic', 'systemicdiastolic', 'systemicmean', 'pasystolic', 'padiastolic', 'pamean', 'st1', 'st2', 'st3', 'icp']\n",
    "# Vitals Shape: 19\n",
    "# Patient Headers: ['patientunitstayid', 'patienthealthsystemstayid', 'gender', 'age', 'ethnicity', 'hospitalid', 'wardid', 'apacheadmissiondx', 'admissionheight', 'hospitaladmittime24', 'hospitaladmitoffset', 'hospitaladmitsource', 'hospitaldischargeyear', 'hospitaldischargetime24', 'hospitaldischargeoffset', 'hospitaldischargelocation', 'hospitaldischargestatus', 'unittype', 'unitadmittime24', 'unitadmitsource', 'unitvisitnumber', 'unitstaytype', 'admissionweight', 'dischargeweight', 'unitdischargetime24', 'unitdischargeoffset', 'unitdischargelocation', 'unitdischargestatus', 'uniquepid']\n",
    "# Patient Shape: 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c30622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of vitalperiodicid column:\n",
      "0    37376747\n",
      "1    37404957\n",
      "2    37385871\n",
      "3    37401664\n",
      "4    37377404\n",
      "5    37394164\n",
      "6    37374753\n",
      "7    37438070\n",
      "8    37425591\n",
      "9    37393215\n",
      "Name: vitalperiodicid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print example how what is inside \"vitalperiodicid\" col of vitalPeriodic.csv\n",
    "vitals_path = os.path.join(DATA_PATH, VITALS_DATA_PATH)\n",
    "vitals_df = pd.read_csv(vitals_path, nrows=50)\n",
    "print(\"Example of vitalperiodicid column:\")\n",
    "print(vitals_df[\"vitalperiodicid\"].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce23ebb",
   "metadata": {},
   "source": [
    "# BUILD DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548fea4",
   "metadata": {},
   "source": [
    "## Build a stay-level infection-evidence table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d3957",
   "metadata": {},
   "source": [
    "| Tier                                | Tag value | Definition (AND/OR logic)                                                                                                                                                     | Typical PPV / Sensitivity\\*                                           | Keep / Drop |\n",
    "| ----------------------------------- | --------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | ----------- |\n",
    "| **Tier 5 â€“ Definite infection**     | **5**     | (a) Explicit sepsis/septic-shock ICD-9 **OR** 038.\\* septicemia **AND** (b) positive blood/sterile culture within Â±24 h of the code **AND** (c) â‰¥ 4 d of systemic antibiotics | PPV â‰ˆ 0.95, Sens â‰ˆ 0.55([PMC][1], [physionet.org][2])                 | **Keep**    |\n",
    "| **Tier 4 â€“ Probable infection**     | 4         | Any one of: explicit sepsis code **OR** positive culture **OR** â‰¥ 2 d IV/PO antibiotics **AND** ICD-9 from infectious-disease chapter 001â€“139                                 | PPV â‰ˆ 0.85, Sens â‰ˆ 0.75([PMC][3], [PMC][4])                           | maybe       |\n",
    "| **Tier 3 â€“ Possible infection**     | 3         | Antibiotics â‰¥ 2 d **OR** infectious ICD-9 alone **OR** positive culture alone                                                                                                 | Balanced set; noisy                                                   | maybe       |\n",
    "| **Tier 2 â€“ Probably non-infected**  | 2         | â‰¤ 1 d antibiotic exposure **AND** no infection codes **AND** all cultures negative/no cultures                                                                                | PPV â‰ˆ 0.25, Sens â‰ˆ 0.90 (non-inf.)([jamanetwork.com][5])              | maybe       |\n",
    "| **Tier 1 â€“ Definite non-infection** | **1**     | **No** infection ICD-9 **AND** **no** antibiotics **AND** no cultures drawn                                                                                                   | Specificity > 0.95 for â€œcleanâ€ stays (e.g., elective CABG) ([PMC][6]) | **Keep**    |\n",
    "\n",
    "[1]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4403835/?utm_source=chatgpt.com \"Validity of administrative data in recording sepsis: a systematic review\"\n",
    "[2]: https://physionet.org/content/eicu-crd-demo/2.0.1/microLab.csv.gz?utm_source=chatgpt.com \"microLab.csv.gz - eICU Collaborative Research Database Demo\"\n",
    "[3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8217098/?utm_source=chatgpt.com \"Determining the Electronic Signature of Infection in Electronic Health ...\"\n",
    "[4]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3568444/?utm_source=chatgpt.com \"Identifying Patients with Severe Sepsis Using Administrative Claims\"\n",
    "[5]: https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2768537?utm_source=chatgpt.com \"Assessment of ICD-9 Diagnosis Codes to Identify Pneumonia ...\"\n",
    "[6]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6132188/?utm_source=chatgpt.com \"The eICU Collaborative Research Database, a freely available multi ...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbe9458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\orosh\\AppData\\Local\\Temp\\ipykernel_24300\\4001151145.py:14: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  dx[\"infect_txt\"]  = dx[\"diagnosisstring\"].fillna(\"\").str.contains(txt_re)\n",
      "C:\\Users\\orosh\\AppData\\Local\\Temp\\ipykernel_24300\\4001151145.py:45: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  med[\"is_abx\"] = med[\"drugname\"].fillna(\"\").str.contains(abx_pat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infection Tag Counts:\n",
      "infection_tag\n",
      "3    50493\n",
      "1    15747\n",
      "4    15152\n",
      "2     5917\n",
      "5       69\n",
      "Name: count, dtype: int64\n",
      "NaN count in infection_tag column: 0\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1-A  Diagnosis evidence ---------------------------------------\n",
    "dx_cols = [\"patientunitstayid\", \"diagnosisoffset\",\n",
    "           \"icd9code\", \"diagnosisstring\"]\n",
    "dx = pd.read_csv(os.path.join(DATA_PATH, \"diagnosis.csv.gz\"),\n",
    "                 usecols=dx_cols, low_memory=False)\n",
    "\n",
    "INFECT_PREFIX = [f\"{i:03d}\" for i in range(1,140)]                # 001-139\n",
    "EXPLICIT = {\"99591\", \"99592\", \"78552\", \"038\"}                     # sepsis / septicemia\n",
    "txt_re  = re.compile(r\"(sepsis|infection|pneumonia|bacteremia|cellulitis)\",\n",
    "                     re.I)\n",
    "\n",
    "dx[\"infect_code\"] = dx[\"icd9code\"].astype(str).str[:3].isin(INFECT_PREFIX)\n",
    "dx[\"explicit\"]    = dx[\"icd9code\"].astype(str).str.replace(\".\", \"\").isin(EXPLICIT)\n",
    "dx[\"infect_txt\"]  = dx[\"diagnosisstring\"].fillna(\"\").str.contains(txt_re)\n",
    "\n",
    "onset_dx = (dx[dx[\"infect_code\"] | dx[\"infect_txt\"]]\n",
    "            .groupby(\"patientunitstayid\")[\"diagnosisoffset\"]\n",
    "            .min()\n",
    "            .rename(\"onset_dx\"))\n",
    "\n",
    "# ---------- 1-B  Culture evidence -----------------------------------------\n",
    "lab_cols = [\"patientunitstayid\", \"culturetakenoffset\", \"organism\"]\n",
    "lab = pd.read_csv(os.path.join(DATA_PATH, \"microLab.csv.gz\"),\n",
    "                  usecols=lab_cols, low_memory=False)\n",
    "\n",
    "lab[\"pos_cx\"] = lab[\"organism\"].fillna(\"\").str.strip().str.lower().ne(\"\") & \\\n",
    "                lab[\"organism\"].str.contains(r\"no growth\", case=False, na=False).eq(False)\n",
    "\n",
    "onset_cx = (lab[lab[\"pos_cx\"]]\n",
    "            .groupby(\"patientunitstayid\")[\"culturetakenoffset\"]\n",
    "            .min()\n",
    "            .rename(\"onset_cx\"))\n",
    "\n",
    "# ---------- 1-C  Antibiotic evidence --------------------------------------\n",
    "abx_pat = re.compile(\n",
    "    r\"(cef|ceph|penem|piperacillin|tazo|penicillin|vanco|linezolid|\"\n",
    "    r\"azithro|levo|cipro|clinda|flagyl|meropenem|imipenem|unasyn|zosyn)\",\n",
    "    re.I)\n",
    "\n",
    "med_cols = [\"patientunitstayid\", \"drugstartoffset\",'drugstopoffset',\n",
    "            \"drugname\", \"drugordercancelled\"]\n",
    "med = pd.read_csv(os.path.join(DATA_PATH, \"medication.csv.gz\"),\n",
    "                  usecols=med_cols, low_memory=False)\n",
    "\n",
    "med[\"is_abx\"] = med[\"drugname\"].fillna(\"\").str.contains(abx_pat)\n",
    "med = med[(med[\"is_abx\"]) & (med[\"drugordercancelled\"].fillna(\"No\").str.lower() != \"yes\")]\n",
    "\n",
    "# treat missing stop-offset as 24 h duration or ICU discharge\n",
    "med['drugstopoffset'] = med['drugstopoffset'].fillna(med['drugstartoffset'] + 1440)\n",
    "med['dot_minutes']    = med['drugstopoffset'] - med['drugstartoffset']\n",
    "# abx_days   = (med.groupby(\"patientunitstayid\").size()\n",
    "#                       .div(48)                             # rough 30-min-bin â†’ day\n",
    "#                       .rename(\"abx_days\"))\n",
    "abx_days = (med.groupby('patientunitstayid')['dot_minutes']\n",
    "                  .sum()\n",
    "                  .div(1440)          # minutes â†’ days\n",
    "                  .rename('abx_days'))\n",
    "# The eICU docs stress that medication rows are orders, not infusions;\n",
    "# summing the elapsed minutes between drugstartoffset and drugstopoffset gives a closer DOT estimate.\n",
    "\n",
    "abx_first  = (med.groupby(\"patientunitstayid\")[\"drugstartoffset\"].min()\n",
    "                         .rename(\"onset_abx\"))\n",
    "\n",
    "# ---------- 1-D  Assemble evidence & tier tag -----------------------------\n",
    "evidence = pd.concat([onset_dx, onset_cx, abx_first, abx_days], axis=1).fillna(0)\n",
    "\n",
    "def tag(r):\n",
    "    if r.abx_days >= 4 and r.onset_cx > 0 and r.onset_dx > 0:\n",
    "        return 5                                           # definite\n",
    "    if (r.onset_dx > 0 and r.abx_days >= 2) or r.onset_cx > 0:\n",
    "        return 4                                           # probable\n",
    "    if (r.abx_days >= 2) or (r.onset_dx > 0):\n",
    "        return 3                                           # possible\n",
    "    if (r.abx_days <= 1) and r.onset_dx == 0 and r.onset_cx == 0:\n",
    "        return 1                                           # definite clean\n",
    "    return 2                                               # probably clean\n",
    "\n",
    "evidence[\"infection_tag\"] = evidence.apply(tag, axis=1).astype(\"int8\")\n",
    "\n",
    "# Earliest onset among any evidence type\n",
    "evidence[\"infection_onset\"] = evidence[[\"onset_dx\", \"onset_cx\", \"onset_abx\"]].\\\n",
    "                                 replace(0, np.nan).min(axis=1)\n",
    "evidence.reset_index(inplace=True)     # â†’ patientunitstayid column\n",
    "\n",
    "# Why this mix? Explicit sepsis ICD-9 codes are highly specific but miss cases; \n",
    "# adding culture and â‰¥ 4 days of antibiotics matches the CDC â€œAdult Sepsis Eventâ€ \n",
    "# definition for presumed infection and restores sensitivity while still keeping PPV high.\n",
    "\n",
    "#Print the qty of each tag\n",
    "print(\"Infection Tag Counts:\")\n",
    "print(evidence[\"infection_tag\"].value_counts())\n",
    "\n",
    "# Check if there are any NaN values in the infection_tag column\n",
    "nan_count = evidence[\"infection_tag\"].isna().sum()\n",
    "print(\"NaN count in infection_tag column:\", nan_count)\n",
    "# # How many stays hit each criterion?\n",
    "# crit = evidence.assign(\n",
    "#     has_sepsis_code = evidence['onset_dx']>0,\n",
    "#     pos_culture     = evidence['onset_cx']>0,\n",
    "#     abx_ge2         = evidence['abx_days']>=2,\n",
    "#     abx_ge4         = evidence['abx_days']>=4\n",
    "# )\n",
    "\n",
    "# summary = crit[['has_sepsis_code','pos_culture','abx_ge2','abx_ge4']].mean()\n",
    "# print(summary)          # shows prevalence of each rule\n",
    "# print('all three (4-day rule):',\n",
    "#       ((crit.has_sepsis_code)&(crit.pos_culture)&(crit.abx_ge4)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d86f7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the evidence DataFrame to a CSV file\n",
    "evidence_path = os.path.join(OUTPUT_PATH, \"evidence.csv.gz\")\n",
    "evidence.to_csv(evidence_path, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c73c2eac-7925-4baf-a181-89f0bd023d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Vitals Data: 147it [34:07, 13.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# columns to read from vitalPeriodic.csv\n",
    "vitals_columns_to_use = [\n",
    "    \"patientunitstayid\",   # ICU stay identifier            - Necessary\n",
    "    \"observationoffset\",   # minutes since unit admission   - Necessary\n",
    "    \"temperature\",         # Â°C                             - Always keep\n",
    "    \"heartrate\",           # beats/min                      - Always keep\n",
    "    \"respiration\",         # breaths/min                    - Always keep\n",
    "    \"sao2\",                # percent SpO2                   - Keep if sensor coverage â‰¥ 80 %\n",
    "    \"systemicsystolic\",    # mmHg                           - Keep (at least MAP or SBP)\n",
    "    \"systemicdiastolic\",   # mmHg                           - Keep (at least MAP or SBP)\n",
    "    \"systemicmean\",        # mmHg (MAP)                     - Keep (at least MAP or SBP)\n",
    "    \"etco2\",               # mmHg                           - Useful but optional (coverage ~10 %)\n",
    "    \"cvp\"                  # mmHg                           - Consider only if â‰¥ 15 % present\n",
    "]\n",
    "\n",
    "'''\n",
    "| Scenario                   | Columns to keep                                                                  | Typical AUROC hit\\*                                                                        |\n",
    "| -------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------ |\n",
    "| **Core model (6 vars)**    | temperature, respiration, heartrate, systemicmean (or SBP/DBP pair), sao2, etco2 | < 2 % lower than full set in published eICU/TB-LSTM tests                                  |\n",
    "| **Slim model (4 vars)**    | temperature, respiration, heartrate, systemicmean                                | \\~4 % lower AUROC but still > 0.80 in most tree-based models                               |\n",
    "| **Ultra-minimal (3 vars)** | temperature, respiration, heartrate                                              | Good for embedded / streaming; catches 70-80 % of cases that meet SIRS in eICU simulations |\n",
    "'''\n",
    "\n",
    "base_columns = [\n",
    "    \"patientunitstayid\",   # ICU stay identifier            - Necessary\n",
    "    \"observationoffset\",   # minutes since unit admission   - Necessary\n",
    "]\n",
    "\n",
    "scenarios = {\n",
    "    \"core\": [\n",
    "        \"temperature\",\n",
    "        \"respiration\",\n",
    "        \"heartrate\",\n",
    "        # \"systemicsystolic\",\n",
    "        # \"systemicdiastolic\", \n",
    "        \"systemicmean\",  # MAP\n",
    "        \"sao2\",\n",
    "        # \"etco2\", # Removed because of low coverage (~3 %)\n",
    "    ],\n",
    "    \"slim\": [\n",
    "        \"temperature\",\n",
    "        \"respiration\",\n",
    "        \"heartrate\",\n",
    "        \"systemicmean\",\n",
    "    ],\n",
    "    \"ultra_minimal\": [\n",
    "        \"temperature\",\n",
    "        \"respiration\",\n",
    "        \"heartrate\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "columns_to_keep = base_columns + scenarios[SCENARIO]\n",
    "\n",
    "# nice, short analytic names\n",
    "vitals_rename_dict = {\n",
    "    \"patientunitstayid\": \"stay_id\",\n",
    "    \"observationoffset\": \"offset_min\",\n",
    "    \"temperature\":       \"temp_c\",\n",
    "    \"heartrate\":         \"HR_bpm\",\n",
    "    \"respiration\":       \"RR_bpm\",\n",
    "    \"sao2\":              \"spo2_pct\",\n",
    "    \"systemicsystolic\":  \"SYS_mmHg\",\n",
    "    \"systemicdiastolic\": \"DIA_mmHg\",\n",
    "    \"systemicmean\":      \"MAP_mmHg\",\n",
    "    \"etco2\":             \"etco2_mmHg\",\n",
    "    \"cvp\":               \"cvp_mmHg\"\n",
    "}\n",
    "\n",
    "# memory-efficient dtypes (32-bit floats; integer IDs)\n",
    "vitals_dtypes = {\n",
    "    \"patientunitstayid\": \"int32\",\n",
    "    \"observationoffset\": \"int32\",\n",
    "    \"temperature\":       \"float32\",\n",
    "    \"heartrate\":         \"int32\",\n",
    "    \"respiration\":       \"int32\",\n",
    "    \"sao2\":              \"int32\",\n",
    "    \"systemicsystolic\":  \"int32\",\n",
    "    \"systemicdiastolic\": \"int32\",\n",
    "    \"systemicmean\":      \"int32\",\n",
    "    \"etco2\":             \"int32\",\n",
    "    \"cvp\":               \"int32\"\n",
    "}\n",
    "\n",
    "# Column: patientunitstayid, Average difference: 0.00, Coverage: 100.00%, Coverage per patient: 100.00%\n",
    "# Column: observationoffset, Average difference: 0.00, Coverage: 100.00%, Coverage per patient: 100.00%\n",
    "# Column: temperature, Average difference: 0.25, Coverage: 7.25%, Coverage per patient: 8.11%\n",
    "# Column: sao2, Average difference: 0.00, Coverage: 90.19%, Coverage per patient: 97.95%\n",
    "# Column: heartrate, Average difference: 0.00, Coverage: 99.55%, Coverage per patient: 99.66%\n",
    "# Column: respiration, Average difference: 0.00, Coverage: 85.86%, Coverage per patient: 90.46%\n",
    "# Column: cvp, Average difference: 0.00, Coverage: 11.78%, Coverage per patient: 13.45%\n",
    "# Column: etco2, Average difference: 0.00, Coverage: 3.22%, Coverage per patient: 3.96%\n",
    "# Column: systemicsystolic, Average difference: 0.00, Coverage: 18.59%, Coverage per patient: 23.63%\n",
    "# Column: systemicdiastolic, Average difference: 0.00, Coverage: 18.59%, Coverage per patient: 23.63%\n",
    "# Column: systemicmean, Average difference: 0.00, Coverage: 18.73%, Coverage per patient: 23.76%\n",
    "\n",
    "# reading in chunks because of memory limitations\n",
    "chunk_size = 1_000_000       # rows\n",
    "out_dir    = os.path.join(OUTPUT_PATH, \"agg_parts\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "part = 0                      # incremental file counter\n",
    "for chunk in tqdm(\n",
    "        pd.read_csv(\n",
    "            os.path.join(DATA_PATH, VITALS_DATA_PATH),\n",
    "            usecols=columns_to_keep,\n",
    "            chunksize=chunk_size\n",
    "        ),\n",
    "        desc=\"Loading Vitals Data\"):\n",
    "\n",
    "    # --- 1. rename columns for readability --------------------------------\n",
    "    chunk.rename(columns=vitals_rename_dict, inplace=True)     # stay_id, offset_min, ...\n",
    "\n",
    "    #DEBUG: Print all column name\n",
    "    # print(\"Columns in chunk:\", chunk.columns.tolist())\n",
    "\n",
    "    # --- 2. build a real time index (needed for resample) ------------------\n",
    "    #print offset min and max\n",
    "    # print(\"Offset min:\", chunk[\"offset_min\"].min(), \"Offset max:\", chunk[\"offset_min\"].max())\n",
    "    chunk['ts'] = pd.to_timedelta(chunk['offset_min'], unit='m')\n",
    "    chunk = chunk.set_index('ts')\n",
    "\n",
    "    # --- 3. 30-minute aggregation -----------------------------------------\n",
    "    #Add these extra columns (per 30-min window)\n",
    "    '''\n",
    "        - temp_std30, temp_range30, temp_slope30h1  #   Fast swings and diurnal drift flag occult infection.\n",
    "        - HR_std30, HR_sdnn30, HR_delta_prev        #   HRV metrics and sudden tachycardia bursts.\n",
    "        - RR_std30, RR_range30                      #   Tachypnea variability rises before hypoxia.\n",
    "        - spo2_cv30, spo2_min30                     #   Desaturation variability predicts pulmonary source.\n",
    "        - MAP_std30, MAP_slope30h1                  #\tMicro-hypotensive dips precede shock.\n",
    "    '''\n",
    "\n",
    "    agg = {\n",
    "        'temp_c':   ['mean', 'std', 'max', 'min'],\n",
    "        'HR_bpm':   ['mean', 'std', 'max'],\n",
    "        'RR_bpm':   ['mean', 'std', 'max', 'min'],\n",
    "        'MAP_mmHg': ['mean', 'std'],\n",
    "        'spo2_pct': ['mean', 'std', 'min'],\n",
    "    }\n",
    "\n",
    "    agg_30 = (chunk\n",
    "            .groupby('stay_id')\n",
    "            .resample('30min')                 # use 'min' instead of deprecated 'T'\n",
    "            .agg(agg)\n",
    "            .drop(columns=['offset_min'], errors='ignore')   # harmless if absent\n",
    "            )\n",
    "\n",
    "    # flatten MultiIndex columns â†’ e.g. temp_c_mean\n",
    "    agg_30.columns = ['_'.join(col) for col in agg_30.columns.to_flat_index()]\n",
    "\n",
    "    # --- 4. derived window-level dynamics ----------------------------------\n",
    "    # range & coefficient of variation (CV = std / mean)\n",
    "    agg_30['temp_range30'] = agg_30['temp_c_max'] - agg_30['temp_c_min']\n",
    "    agg_30['RR_range30']   = agg_30['RR_bpm_max']  - agg_30['RR_bpm_min']\n",
    "    agg_30['spo2_cv30']    = agg_30['spo2_pct_std'] / agg_30['spo2_pct_mean']\n",
    "    agg_30['HR_sdnn30']    = agg_30['HR_bpm_std']          # SDNN proxy\n",
    "\n",
    "    # slope / delta (per hour; 30-min step = 0.5 h)\n",
    "    for base in ['temp_c_mean', 'HR_bpm_mean', 'RR_bpm_mean', 'MAP_mmHg_mean']:\n",
    "        agg_30[f\"{base.replace('_mean','')}_slope30h1\"] = (\n",
    "            agg_30.groupby('stay_id')[base].diff() / 0.5\n",
    "        )\n",
    "    agg_30['HR_delta_prev'] = agg_30.groupby('stay_id')['HR_bpm_mean'].diff()\n",
    "    agg_30['MAP_slope30h1'] = agg_30['MAP_mmHg_std'] / agg_30['MAP_mmHg_mean']\n",
    "\n",
    "    # --- 5. LOCF forward-fill, limit 1 -------------------------------------\n",
    "    agg_30 = (agg_30\n",
    "              .groupby('stay_id')\n",
    "              .ffill(limit=1)            # fill at most the next 30-min slot\n",
    "              .reset_index()             # bring stay_id & ts back as columns\n",
    "             )\n",
    "    \n",
    "    # restore the original offset_min column\n",
    "    # agg_30['offset_min'] = offset_min_col\n",
    "    agg_30['offset_min'] = (agg_30['ts']\n",
    "                            .dt.total_seconds()\n",
    "                            .div(60)\n",
    "                            .astype('int32'))\n",
    "    \n",
    "    # print(\"Aggset min:\", agg_30[\"offset_min\"].min(), \"Offset max:\", agg_30[\"offset_min\"].max())\n",
    "\n",
    "    # --- 5.1. Keep only the relevant columns -------------------------------\n",
    "    # Keep only the columns we need\n",
    "    #Add these extra columns (per 30-min window)\n",
    "    '''\n",
    "        - temp_std30, temp_range30, temp_slope30h1  #   Fast swings and diurnal drift flag occult infection.\n",
    "        - HR_std30, HR_sdnn30, HR_delta_prev        #   HRV metrics and sudden tachycardia bursts.\n",
    "        - RR_std30, RR_range30                      #   Tachypnea variability rises before hypoxia.\n",
    "        - spo2_cv30, spo2_min30                     #   Desaturation variability predicts pulmonary source.\n",
    "        - MAP_std30, MAP_slope30h1                  #\tMicro-hypotensive dips precede shock.\n",
    "    '''\n",
    "\n",
    "    agg_30 = agg_30[[\n",
    "        'stay_id', 'ts', 'offset_min',\n",
    "        'temp_c_mean', 'temp_c_std', 'temp_range30', 'temp_c_slope30h1',\n",
    "        'HR_bpm_mean', 'HR_bpm_std', 'HR_sdnn30', 'HR_delta_prev',\n",
    "        'RR_bpm_mean', 'RR_bpm_std', 'RR_range30',\n",
    "        'MAP_mmHg_mean', 'MAP_mmHg_std', 'MAP_slope30h1',\n",
    "        'spo2_pct_mean', 'spo2_pct_std', 'spo2_cv30', 'spo2_pct_min'\n",
    "    ]]\n",
    "\n",
    "    # --- 6. Merge with infection times ----------------------------------\n",
    "    # merge the onset table\n",
    "    agg_30 = agg_30.merge(\n",
    "                evidence[[\"patientunitstayid\", \"infection_tag\", \"infection_onset\"]],\n",
    "                left_on=\"stay_id\",\n",
    "                right_on=\"patientunitstayid\",\n",
    "                how=\"left\"\n",
    "            )\n",
    "\n",
    "    # binary 0/1 flag\n",
    "    agg_30[\"infected\"] = (\n",
    "            agg_30[\"infection_onset\"].notna() &\n",
    "            (agg_30[\"offset_min\"] >= agg_30[\"infection_onset\"])\n",
    "        ).astype(\"int8\")\n",
    "\n",
    "    # keep only what the time-series file needs\n",
    "    agg_30.drop(columns=[\"infection_tag\", \"infection_onset\", \"patientunitstayid\"],\n",
    "                inplace=True)\n",
    "\n",
    "    # --- 7. persist this part to disk --------------------------------------\n",
    "    part_file = os.path.join(out_dir, f\"vitals_30min_part_{part:04d}.parquet\")\n",
    "    agg_30.to_parquet(part_file, index=False)\n",
    "    part += 1\n",
    "\n",
    "    # #DEBUG: Stop after 5 chunks\n",
    "    # if part == 1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9baaa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Vitals Parts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147/147 [00:10<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   stay_id              ts  offset_min  temp_c_mean  temp_c_std  temp_range30  \\\n",
      "0   141168 0 days 01:59:00         119          NaN         NaN           NaN   \n",
      "1   141168 0 days 02:29:00         149          NaN         NaN           NaN   \n",
      "2   141168 0 days 02:59:00         179          NaN         NaN           NaN   \n",
      "3   141168 0 days 03:29:00         209          NaN         NaN           NaN   \n",
      "4   141168 0 days 03:59:00         239          NaN         NaN           NaN   \n",
      "\n",
      "   temp_c_slope30h1  HR_bpm_mean  HR_bpm_std  HR_sdnn30  ...  RR_bpm_std  \\\n",
      "0               NaN   140.000000    0.000000   0.000000  ...         NaN   \n",
      "1               NaN   134.666667    3.011091   3.011091  ...         NaN   \n",
      "2               NaN   134.333333    0.816497   0.816497  ...         NaN   \n",
      "3               NaN   134.000000    0.000000   0.000000  ...         NaN   \n",
      "4               NaN   133.000000    1.095445   1.095445  ...         NaN   \n",
      "\n",
      "   RR_range30  MAP_mmHg_mean  MAP_mmHg_std  MAP_slope30h1  spo2_pct_mean  \\\n",
      "0         NaN            NaN           NaN            NaN           93.0   \n",
      "1         NaN            NaN           NaN            NaN           93.0   \n",
      "2         NaN            NaN           NaN            NaN            NaN   \n",
      "3         NaN            NaN           NaN            NaN           64.0   \n",
      "4         NaN            NaN           NaN            NaN           75.0   \n",
      "\n",
      "   spo2_pct_std  spo2_cv30  spo2_pct_min  infected  \n",
      "0           NaN        NaN          93.0         0  \n",
      "1           NaN        NaN          93.0         0  \n",
      "2           NaN        NaN           NaN         0  \n",
      "3     15.556349   0.243068          53.0         0  \n",
      "4     15.556349   0.243068          75.0         0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Shape of df_vitals: (25174325, 22)\n",
      "Individual stay_ids: 192831\n",
      "Number of infected patients: 81099\n"
     ]
    }
   ],
   "source": [
    "#Concatenate all the parts\n",
    "out_dir = os.path.join(OUTPUT_PATH, \"agg_parts\")\n",
    "agg_parts = []\n",
    "for part in tqdm(\n",
    "        os.listdir(out_dir),\n",
    "        desc=\"Loading Vitals Parts\"):\n",
    "    part_file = os.path.join(out_dir, part)\n",
    "    agg_parts.append(pd.read_parquet(part_file))\n",
    "df_vitals = pd.concat(agg_parts, ignore_index=True)\n",
    "#print head\n",
    "print(df_vitals.head())\n",
    "#TODO: Save dataset, static data\n",
    "#Save the evidence DataFrame to a CSV file\n",
    "print(\"Shape of df_vitals:\", df_vitals.shape)\n",
    "print(\"Individual stay_ids:\", df_vitals[\"stay_id\"].nunique())\n",
    "#count the number of patients with at least one infected row\n",
    "infected_patients = df_vitals[df_vitals[\"infected\"] == 1][\"stay_id\"].nunique()\n",
    "print(\"Number of infected patients:\", infected_patients)\n",
    "vitals_path = os.path.join(OUTPUT_PATH, \"vitals.csv.gz\")\n",
    "df_vitals.to_csv(vitals_path, index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea5f1c",
   "metadata": {},
   "source": [
    "| Keep?                                      | Column(s)                                                                                                                                             | Rationale                                                                                                                                   |\n",
    "| ------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **âœ… Keep**                                 | `age`                                                                                                                                                 | Infection and sepsis risk rise sharply above 65 y; age is independent of acute physiology in risk models ([PMC][1]).                        |\n",
    "| **âœ… Keep**                                 | `gender`                                                                                                                                              | Large multicentre studies show sex-specific mortality and treatment gaps in septic patients ([PMC][2]).                                     |\n",
    "| **âœ… Keep**                                 | `admissionweight` (or BMI)                                                                                                                            | Obesity associates with higher device-related infection rates and dosing challenges ([PMC][3]).                                             |\n",
    "| **âœ… Keep**                                 | `apacheadmissiondx` (high-level diagnosis *without* using the actual APACHE score)                                                                    | Captures surgical vs. medical cases and baseline organ focus; improves discrimination without leaking future SOFA/APACHE values ([PMC][1]). |\n",
    "| **âœ… Keep (categorical one-hot/embedding)** | `unitadmitsource`, `hospitaladmitsource`, `unittype`                                                                                                  | Infection incidence differs between direct-ED admits, ward transfers and surgical ICUs ([PMC][4]).                                          |\n",
    "| **ðŸ”¶ Consider**                            | `ethnicity`                                                                                                                                           | Adds modest uplift in some U.S. cohorts; effect sizes smaller than age/sex.                                                                 |\n",
    "| **ðŸš« Drop**                                | IDs (`patientunitstayid`, `patienthealthsystemstayid`, `uniquepid`), discharge-time fields, `hospitaldischarge*`, `unitdischarge*`, `dischargeweight` | Pure identifiers or post-event information â†’ no predictive value or label leakage.                                                          |\n",
    "| **ðŸš« Drop**                                | `hospitalid`, `wardid`                                                                                                                                | Site effects are large; unless you explicitly model site-level random effects, they can overfit.                                            |\n",
    "\n",
    "[1]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3580738/?utm_source=chatgpt.com \"Risk assessment in sepsis: a new prognostication rule by APACHE II ...\"\n",
    "[2]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3322379/?utm_source=chatgpt.com \"Gender Differences in Mortality in Patients with Severe Sepsis and ...\"\n",
    "[3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8340548/?utm_source=chatgpt.com \"Impact of Obesity in Critical Illness - PMC - PubMed Central\"\n",
    "[4]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3862707/?utm_source=chatgpt.com \"Incidence of healthcare associated infection in the surgical ICU of a ...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c1b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Patient DataFrame:\n",
      "    stay_id  gender                                           admit_dx  \\\n",
      "0    141168  Female      Rhythm disturbance (atrial, supraventricular)   \n",
      "1    141179  Female                                                NaN   \n",
      "2    141194    Male              Sepsis, renal/UTI (including bladder)   \n",
      "3    141196    Male                                                NaN   \n",
      "4    141197    Male                                  Sepsis, pulmonary   \n",
      "5    141203  Female       Arrest, respiratory (without cardiac arrest)   \n",
      "6    141208  Female  Overdose, sedatives, hypnotics, antipsychotics...   \n",
      "7    141227    Male                                  Sepsis, pulmonary   \n",
      "8    141229  Female                      CHF, congestive heart failure   \n",
      "9    141233  Female                           Mitral valve replacement   \n",
      "10   141244    Male                    Graft, femoral-popliteal bypass   \n",
      "11   141260  Female                                             Asthma   \n",
      "12   141263    Male                                                NaN   \n",
      "13   141264    Male                                   Head only trauma   \n",
      "14   141265    Male               CVA, cerebrovascular accident/stroke   \n",
      "15   141266    Male              Sepsis, renal/UTI (including bladder)   \n",
      "16   141276  Female       Arrest, respiratory (without cardiac arrest)   \n",
      "17   141284    Male                                             Anemia   \n",
      "18   141288  Female                                  Sepsis, pulmonary   \n",
      "19   141289  Female                                       Pneumothorax   \n",
      "20   141296    Male  Hypovolemia (including dehydration, Do not inc...   \n",
      "21   141297    Male                                  Sepsis, pulmonary   \n",
      "22   141304    Male                                  Sepsis, pulmonary   \n",
      "23   141313    Male                        Aneurysm, dissecting aortic   \n",
      "24   141314    Male           Aneurysm, abdominal aortic; with rupture   \n",
      "25   141328  Female                      CHF, congestive heart failure   \n",
      "26   141329    Male                  Infarction, acute myocardial (MI)   \n",
      "27   141337  Female                      Thoracotomy for other reasons   \n",
      "28   141340  Female                             Transphenoidal surgery   \n",
      "29   141360    Male               CVA, cerebrovascular accident/stroke   \n",
      "30   141362    Male  Cholecystectomy/cholangitis, surgery for (gall...   \n",
      "31   141366    Male                         Respiratory surgery, other   \n",
      "32   141373    Male                            Endarterectomy, carotid   \n",
      "33   141392  Female              Sepsis, renal/UTI (including bladder)   \n",
      "34   141415    Male                   Thrombosis, vascular (deep vein)   \n",
      "35   141432    Male                                  Sepsis, pulmonary   \n",
      "36   141433    Male                                                NaN   \n",
      "37   141436    Male       Arrest, respiratory (without cardiac arrest)   \n",
      "38   141448    Male  Coma/change in level of consciousness (for hep...   \n",
      "39   141451    Male                            Pulmonary valve surgery   \n",
      "\n",
      "       hosp_admit_source     unit_type     unit_admit_source   weight_kg  \\\n",
      "0           Direct Admit  Med-Surg ICU          Direct Admit   84.300003   \n",
      "1   Emergency Department  Med-Surg ICU            ICU to SDU         NaN   \n",
      "2                  Floor         CTICU                 Floor   73.900002   \n",
      "3   Emergency Department  Med-Surg ICU            ICU to SDU         NaN   \n",
      "4   Emergency Department  Med-Surg ICU  Emergency Department  102.099998   \n",
      "5                  Floor  Med-Surg ICU                 Floor   70.199997   \n",
      "6   Emergency Department  Med-Surg ICU  Emergency Department   95.300003   \n",
      "7                  Floor  Med-Surg ICU                 Floor   82.199997   \n",
      "8   Emergency Department  Med-Surg ICU  Emergency Department   89.800003   \n",
      "9         Operating Room         CTICU        Operating Room   61.700001   \n",
      "10        Operating Room         CTICU        Operating Room   92.300003   \n",
      "11  Emergency Department  Med-Surg ICU  Emergency Department   69.900002   \n",
      "12                   NaN  Med-Surg ICU            ICU to SDU         NaN   \n",
      "13                   NaN  Med-Surg ICU  Emergency Department         NaN   \n",
      "14          Direct Admit  Med-Surg ICU          Direct Admit  100.000000   \n",
      "15  Emergency Department  Med-Surg ICU  Emergency Department  120.400002   \n",
      "16        Operating Room  Med-Surg ICU          Direct Admit  156.600006   \n",
      "17          Direct Admit         CTICU          Direct Admit         NaN   \n",
      "18  Emergency Department  Med-Surg ICU  Emergency Department         NaN   \n",
      "19  Emergency Department  Med-Surg ICU                 Floor         NaN   \n",
      "20                 Floor          SICU                 Floor         NaN   \n",
      "21                 Floor          SICU                 Floor         NaN   \n",
      "22  Emergency Department  Med-Surg ICU  Emergency Department         NaN   \n",
      "23        Other Hospital     CCU-CTICU        Other Hospital         NaN   \n",
      "24        Other Hospital          SICU        Operating Room         NaN   \n",
      "25  Emergency Department          MICU  Emergency Department         NaN   \n",
      "26          Direct Admit     CCU-CTICU          Direct Admit   79.000000   \n",
      "27        Operating Room  Med-Surg ICU        Operating Room   67.800003   \n",
      "28        Operating Room  Med-Surg ICU        Operating Room   70.099998   \n",
      "29  Emergency Department     Neuro ICU  Emergency Department         NaN   \n",
      "30        Operating Room  Med-Surg ICU        Operating Room         NaN   \n",
      "31        Operating Room          MICU        Operating Room  113.900002   \n",
      "32        Operating Room         CTICU        Operating Room   87.500000   \n",
      "33  Emergency Department          MICU  Emergency Department         NaN   \n",
      "34          Direct Admit  Med-Surg ICU          Direct Admit   87.099998   \n",
      "35  Emergency Department  Med-Surg ICU  Emergency Department  131.500000   \n",
      "36  Emergency Department  Med-Surg ICU            ICU to SDU         NaN   \n",
      "37  Emergency Department         CTICU  Emergency Department   72.599998   \n",
      "38  Emergency Department     Neuro ICU  Emergency Department   79.800003   \n",
      "39        Operating Room         CTICU        Operating Room  117.000000   \n",
      "\n",
      "    discharge_offset   age  infection_tag  \n",
      "0               3596  70.0              1  \n",
      "1               2042  52.0              0  \n",
      "2               4813  68.0              2  \n",
      "3               1463  71.0              3  \n",
      "4                 74  71.0              1  \n",
      "5               1869  77.0              3  \n",
      "6                720  25.0              0  \n",
      "7               1652  82.0              4  \n",
      "8                166  90.0              3  \n",
      "9              15685  81.0              1  \n",
      "10              3835  59.0              3  \n",
      "11              1073  43.0              0  \n",
      "12               475  19.0              0  \n",
      "13               292  19.0              0  \n",
      "14              6068  67.0              0  \n",
      "15              1501  73.0              4  \n",
      "16              1684  59.0              0  \n",
      "17              2076  63.0              3  \n",
      "18              1631  61.0              4  \n",
      "19              1283  61.0              3  \n",
      "20              2828  63.0              3  \n",
      "21              1869  63.0              3  \n",
      "22              6639  70.0              4  \n",
      "23               433  45.0              0  \n",
      "24               632  45.0              0  \n",
      "25               611  76.0              0  \n",
      "26              2572  50.0              0  \n",
      "27              1146  72.0              1  \n",
      "28              4229  80.0              2  \n",
      "29              3109  48.0              0  \n",
      "30              3118  65.0              3  \n",
      "31              1339  81.0              1  \n",
      "32              2789  81.0              0  \n",
      "33               961  78.0              4  \n",
      "34              4430  30.0              0  \n",
      "35              1145  75.0              4  \n",
      "36              1354  75.0              0  \n",
      "37              2167  46.0              1  \n",
      "38               983  65.0              0  \n",
      "39              3883  39.0              1  \n",
      "Total number of rows in static_df: 195339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 1â€†â€†Columns to load (add unitDischargeOffset so we can drop short stays)\n",
    "patient_columns_to_use = [\n",
    "    \"patientunitstayid\", \n",
    "    \"age\", \n",
    "    \"gender\", \n",
    "    \"admissionweight\",\n",
    "    \"apacheadmissiondx\", \n",
    "    \"unitadmitsource\", \n",
    "    \"hospitaladmitsource\",\n",
    "    \"unittype\", \n",
    "    \"unitdischargeoffset\"          # LOS in minutes\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 2â€†â€†Memory-efficient dtypes\n",
    "patient_dtypes = {\n",
    "    \"patientunitstayid\"   : \"int32\",\n",
    "    \"age\"                 : \"object\",      # string like \"76\" or \"> 89\"\n",
    "    \"gender\"              : \"category\",\n",
    "    \"admissionweight\"     : \"float32\",\n",
    "    \"apacheadmissiondx\"   : \"category\",\n",
    "    \"unitadmitsource\"     : \"category\",\n",
    "    \"hospitaladmitsource\" : \"category\",\n",
    "    \"unittype\"            : \"category\",\n",
    "    \"unitdischargeoffset\" : \"int32\",\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 3â€†â€†Consistent snake-case column names\n",
    "patient_rename_dict = {\n",
    "    \"patientunitstayid\"   : \"stay_id\",\n",
    "    \"age\"                 : \"age_str\",\n",
    "    \"gender\"              : \"gender\",\n",
    "    \"admissionweight\"     : \"weight_kg\",\n",
    "    \"apacheadmissiondx\"   : \"admit_dx\",\n",
    "    \"unitadmitsource\"     : \"unit_admit_source\",\n",
    "    \"hospitaladmitsource\" : \"hosp_admit_source\",\n",
    "    \"unittype\"            : \"unit_type\",\n",
    "    \"unitdischargeoffset\" : \"discharge_offset\",\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 4â€†â€†Load PATIENT table\n",
    "patient_data = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, PATIENT_DATA_PATH),\n",
    "    usecols     = patient_columns_to_use,\n",
    "    dtype       = patient_dtypes,\n",
    "    low_memory  = False\n",
    ").rename(columns = patient_rename_dict)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 5â€†â€†Convert age string â†’ numeric and drop minors\n",
    "patient_data[\"age\"] = (patient_data[\"age_str\"]\n",
    "                       .str.replace(\"> ?89\", \"90\", regex=True)  # \"> 89\" â†’ 90\n",
    "                       .astype(\"float32\"))\n",
    "patient_data = patient_data[patient_data[\"age\"] >= 18]\n",
    "# Drop the age_str column\n",
    "patient_data.drop(columns=[\"age_str\"], inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 6â€†â€†Drop very short ICU stays (â‰¤ 60 min LOS)\n",
    "MIN_LOS_MIN = 60\n",
    "patient_data = patient_data[patient_data[\"discharge_offset\"] >= MIN_LOS_MIN]\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 7â€†â€†Attach the infection evidence tag (one row per stay_id)\n",
    "static_df = patient_data.merge(\n",
    "    evidence[[\"patientunitstayid\", \"infection_tag\"]]\n",
    "            .rename(columns={\"patientunitstayid\": \"stay_id\"}),\n",
    "    on   = \"stay_id\",\n",
    "    how  = \"left\",\n",
    "    validate = \"one_to_one\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# static_df now has exactly one row per stay_id with:\n",
    "# stay_id | age (float) | gender | weight_kg | admit_dx | unit_admit_source\n",
    "# hosp_admit_source | unit_type | discharge_offset | infection_tag\n",
    "# Save once for downstream modelling\n",
    "# static_df.to_parquet(\n",
    "#     os.path.join(DATA_PATH, \"static_patient_info.parquet\"),\n",
    "#     engine=\"pyarrow\",\n",
    "#     index=False\n",
    "# )\n",
    "# Drop if infection tag is NaN\n",
    "# static_df = static_df.dropna(subset=[\"infection_tag\"])\n",
    "# Fill infection_tag with 0 if NaN\n",
    "static_df[\"infection_tag\"] = static_df[\"infection_tag\"].fillna(0).astype(\"int8\")\n",
    "\n",
    "static_df.to_csv(\n",
    "    os.path.join(OUTPUT_PATH, \"static_patient_info.csv.gz\"),\n",
    "    index=False,\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "\n",
    "# Print the first 40 rows of the static_df DataFrame\n",
    "print(\"Static Patient DataFrame:\")\n",
    "print(static_df.head(40))\n",
    "# Print total number of rows\n",
    "print(\"Total number of rows in static_df:\", len(static_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfde1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compare size of processed vitals and original vitals to see if it makes sense\n",
    "# chunk_size = 1_000_000       # rows\n",
    "# n_rows = 0\n",
    "# n_cols = 0\n",
    "# # Load the original vitals data\n",
    "# # for chunk in tqdm(\n",
    "# #         pd.read_csv(\n",
    "# #             os.path.join(DATA_PATH, VITALS_DATA_PATH),\n",
    "# #             usecols=columns_to_keep,\n",
    "# #             chunksize=chunk_size\n",
    "# #         ),\n",
    "# #         desc=\"Loading Original Vitals Data\"):\n",
    "# #     n_rows += chunk.shape[0]\n",
    "# #     n_cols = chunk.shape[1]\n",
    "# # Print the shape of the original vitals data\n",
    "# print(\"Original Vitals Data Shape:\", (n_rows, n_cols))\n",
    "# # Print the shape of the processed vitals data\n",
    "\n",
    "# #Load processed vitals data\n",
    "# df_vitals = pd.read_csv(vitals_path)\n",
    "\n",
    "# print(\"Processed Vitals Data Shape:\", df_vitals.shape)\n",
    "# # 146,671,642\n",
    "# # 25,174,325\n",
    "\n",
    "# # 146,671,642 / 30 * 5 = 24,445,273\n",
    "# # 25,174,325 * 30 / 5 = 151,045,950 => matches the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da721f08",
   "metadata": {},
   "source": [
    "# REPROCESS\n",
    "Clean vitals data into clean section of 24 hours for each patients, with first 12 hours for label and next 12 to predict, with (if infected) an infection starting around 6h of the prediciton\n",
    "Keep only patients with enough vitals coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ba07a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of infected patients: 81099\n",
      "Number of non-infected patients: 159437\n",
      "Number of patients with at least one empty vitals: {'infected': 30952, 'non_infected': 151315}\n",
      "Number of patients with at least one complete vitals: {'infected': 33401, 'non_infected': 159430}\n"
     ]
    }
   ],
   "source": [
    "#Load vitals data\n",
    "vitals_path = os.path.join(OUTPUT_PATH, \"vitals.csv.gz\")\n",
    "df_vitals = pd.read_csv(vitals_path)\n",
    "# Count how many patients have at least one infection and how many have none\n",
    "infected_patients = df_vitals[df_vitals[\"infected\"] == 1][\"stay_id\"].nunique()\n",
    "non_infected_patients = df_vitals[df_vitals[\"infected\"] == 0][\"stay_id\"].nunique()\n",
    "# Print the number of infected and non-infected patients\n",
    "print(\"Number of infected patients:\", infected_patients)\n",
    "print(\"Number of non-infected patients:\", non_infected_patients)\n",
    "# Count how many infected and non infected patients have at least one of each vitals at any point\n",
    "# Count how many patients have at least one of each vitals at any point\n",
    "# Group by stay_id and count the number of unique values in each column\n",
    "empty = {\n",
    "    \"infected\": 0,\n",
    "    \"non_infected\": 0\n",
    "}\n",
    "complete = {\n",
    "    \"infected\": 0,\n",
    "    \"non_infected\": 0\n",
    "}\n",
    "for stay, group in df_vitals.groupby(\"stay_id\"):\n",
    "    # Explore each column, if one is entirely empty\n",
    "    for col in df_vitals.columns:\n",
    "        if group[col].isna().all():\n",
    "            # If the column is empty, check if the patient is infected or not\n",
    "            if group[\"infected\"].iloc[0] == 1:\n",
    "                empty[\"infected\"] += 1\n",
    "            else:\n",
    "                empty[\"non_infected\"] += 1\n",
    "            break\n",
    "\n",
    "    if group[\"infected\"].iloc[0] == 1:\n",
    "        complete[\"infected\"] += 1\n",
    "    else:\n",
    "        complete[\"non_infected\"] += 1\n",
    "\n",
    "print(\"Number of patients with at least one empty vitals:\", empty)\n",
    "print(\"Number of patients with at least one complete vitals:\", complete)\n",
    "\n",
    "# Number of infected patients: 81099\n",
    "# Number of non-infected patients: 159437\n",
    "# Number of patients with at least one empty vitals: {'infected': 30952, 'non_infected': 151315}\n",
    "# Number of patients with at least one complete vitals: {'infected': 33401, 'non_infected': 159430}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4809ad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of infected patients: 81099\n",
      "Number of infected patients with at least 12 hours before the onset of infection: 11635\n"
     ]
    }
   ],
   "source": [
    "#How many infected patients have at least 12 hours before the onset of infection\n",
    "infected_patients_stay_id = df_vitals[df_vitals[\"infected\"] == 1][\"stay_id\"].unique()\n",
    "infected_patients = 0\n",
    "infected_patients_12h = 0\n",
    "for stay in infected_patients_stay_id:\n",
    "    group = df_vitals[df_vitals[\"stay_id\"] == stay]\n",
    "    group_start_time = group[\"offset_min\"].min()\n",
    "    group_infection_time = group[group[\"infected\"] == 1][\"offset_min\"].min()\n",
    "    time_diff = group_infection_time - group_start_time\n",
    "    if time_diff >= 12*60:\n",
    "        infected_patients_12h += 1\n",
    "    infected_patients += 1\n",
    "print(\"Number of infected patients:\", infected_patients)\n",
    "print(\"Number of infected patients with at least 12 hours before the onset of infection:\", infected_patients_12h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a501b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading first-pass file â€¦\n",
      "Building 24-h windows â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 21959/192831 [1:08:03<8:49:37,  5.38it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m     counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mpick_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_clean_lead\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infected_here \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m, in \u001b[0;36mpick_start\u001b[1;34m(stay)\u001b[0m\n\u001b[0;32m     39\u001b[0m best_left, best_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m left \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(stay\u001b[38;5;241m.\u001b[39moffset_min\u001b[38;5;241m.\u001b[39mmin(),\n\u001b[0;32m     41\u001b[0m                   stay\u001b[38;5;241m.\u001b[39moffset_min\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m-\u001b[39mWIN_H\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m+\u001b[39mstep,\n\u001b[0;32m     42\u001b[0m                   step):\n\u001b[1;32m---> 43\u001b[0m     ok \u001b[38;5;241m=\u001b[39m \u001b[43mstay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset_min\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset_min\u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mWIN_H\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\\\n\u001b[0;32m     45\u001b[0m              \u001b[38;5;241m.\u001b[39mapply(dense_enough, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok \u001b[38;5;241m>\u001b[39m best_bins:\n\u001b[0;32m     47\u001b[0m         best_left, best_bins \u001b[38;5;241m=\u001b[39m left, ok\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\indexing.py:1211\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1209\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1210\u001b[0m inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[0;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    693\u001b[0m             ),\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\orosh\\miniforge3\\envs\\MEWS\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 0â€†â€†paths & constants\n",
    "DATA_DIR    = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\eicu-2.0\\processed\"\n",
    "VITALS_FILE = os.path.join(DATA_DIR, \"vitals.csv.gz\")  # 30-min grid, first pass\n",
    "OUT_DIR     = os.path.join(DATA_DIR, \"24h_windows\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "WIN_H, HIST_H, BIN_MIN  = 24, 12, 30\n",
    "BINS_WIN                = WIN_H*60//BIN_MIN    # 48 rows\n",
    "MIN_DATA_BIN            = 18*60//BIN_MIN       # â‰¥ 18 h usable rows\n",
    "FILL_SMALL, FILL_MED    = 2, 6                 # gap sizes (bins)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "dtype = {'stay_id':'int32', 'offset_min':'int32', 'infected':'int8'}\n",
    "print(\"Reading first-pass file â€¦\")\n",
    "df = pd.read_csv(VITALS_FILE, dtype=dtype, low_memory=False)\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "def dense_enough(row) -> bool:\n",
    "    \"\"\"Row counts as data if at least ONE vital is not NaN.\"\"\"\n",
    "    return row.drop(['stay_id','ts','offset_min','infected']).notna().any()\n",
    "\n",
    "def gap_fill(win: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in win.columns.difference(['stay_id','ts','offset_min','infected']):\n",
    "        s = win[col]\n",
    "        win[col] = (s.interpolate(limit=FILL_SMALL, limit_direction='both')\n",
    "                       .ffill(limit=FILL_MED)\n",
    "                       .bfill(limit=FILL_MED))\n",
    "    return win\n",
    "\n",
    "def pick_start(stay: pd.DataFrame) -> int | None:\n",
    "    onset = stay.offset_min[stay.infected==1].min()  # NaN if clean\n",
    "    step  = BIN_MIN\n",
    "\n",
    "    if math.isnan(onset):                            # non-infected\n",
    "        best_left, best_bins = None, 0\n",
    "        for left in range(stay.offset_min.min(),\n",
    "                          stay.offset_min.max()-WIN_H*60+step,\n",
    "                          step):\n",
    "            ok = stay.loc[(stay.offset_min>=left)&\n",
    "                           (stay.offset_min<left+WIN_H*60)]\\\n",
    "                     .apply(dense_enough, axis=1).sum()\n",
    "            if ok > best_bins:\n",
    "                best_left, best_bins = left, ok\n",
    "        return best_left if best_bins >= MIN_DATA_BIN else None\n",
    "\n",
    "    # ---------- infected stays ----------\n",
    "    for delta in range(6, -1, -1):                  # onset at +6 â€¦ +0 h\n",
    "        left = onset - (HIST_H + delta)*60\n",
    "        if left < 0:\n",
    "            continue\n",
    "        win = stay[(stay.offset_min>=left)&(stay.offset_min<left+WIN_H*60)]\n",
    "        clean_hist = (win.loc[win.offset_min < left+HIST_H*60,'infected'].sum()==0)\n",
    "        enough     = win.apply(dense_enough, axis=1).sum() >= MIN_DATA_BIN\n",
    "        if clean_hist and enough:\n",
    "            return left\n",
    "    # fallback: onset @ prediction t=0\n",
    "    left = onset - HIST_H*60\n",
    "    win  = stay[(stay.offset_min>=left)&(stay.offset_min<left+WIN_H*60)]\n",
    "    return left if left>=0 and win.apply(dense_enough,axis=1).sum()>=MIN_DATA_BIN else None\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "counts = dict(\n",
    "    infect_total=0, noninfect_total=0,\n",
    "    keep_infect=0, keep_noninfect=0,\n",
    "    sparse=0, no_clean_lead=0, short_los=0\n",
    ")\n",
    "samples = []\n",
    "\n",
    "print(\"Building 24-h windows â€¦\")\n",
    "for sid, stay in tqdm(df.groupby('stay_id'), total=df['stay_id'].nunique()):\n",
    "    infected_here = bool(stay['infected'].any())\n",
    "    counts['infect_total' if infected_here else 'noninfect_total'] += 1\n",
    "\n",
    "    if stay.apply(dense_enough, axis=1).sum() < MIN_DATA_BIN:\n",
    "        counts['sparse'] += 1\n",
    "        continue\n",
    "\n",
    "    start = pick_start(stay)\n",
    "    if start is None:\n",
    "        counts['no_clean_lead' if infected_here else 'sparse'] += 1\n",
    "        continue\n",
    "\n",
    "    win = stay[(stay.offset_min>=start)&(stay.offset_min<start+WIN_H*60)].copy()\n",
    "\n",
    "    # left-pad zeros if window does not reach 24 h\n",
    "    lag_bins = (win.offset_min.min()-start)//BIN_MIN\n",
    "    if lag_bins>0:\n",
    "        pad = pd.DataFrame({\n",
    "            'stay_id'   : sid,\n",
    "            'ts'        : pd.NaT,\n",
    "            'offset_min': np.arange(start, win.offset_min.min(), BIN_MIN, dtype='int32'),\n",
    "            'infected'  : 0})\n",
    "        for v in win.columns.difference(pad.columns):\n",
    "            pad[v] = 0\n",
    "        win = pd.concat([pad, win], ignore_index=True, sort=False)\n",
    "\n",
    "    win.sort_values('offset_min', inplace=True)\n",
    "    win = gap_fill(win)\n",
    "    # any still-empty rows â†’ zero\n",
    "    empties = ~win.apply(dense_enough, axis=1)\n",
    "    win.loc[empties, win.columns.difference(['stay_id','ts','offset_min','infected'])] = 0\n",
    "\n",
    "    if len(win) != BINS_WIN:\n",
    "        counts['short_los'] += 1\n",
    "        continue\n",
    "\n",
    "    samples.append(win)\n",
    "    counts['keep_infect' if infected_here else 'keep_noninfect'] += 1\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "print(\"Saving windows â€¦\")\n",
    "pd.concat(samples, ignore_index=True).to_parquet(\n",
    "    os.path.join(OUT_DIR, \"vitals_24h_windows.parquet\"),\n",
    "    engine=\"pyarrow\", index=False\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "#  summary\n",
    "print(\"\\n==============  SUMMARY  ==============\")\n",
    "print(f\"Infected stays   : {counts['infect_total']}\")\n",
    "print(f\"  windows kept   : {counts['keep_infect']}  \"\n",
    "      f\"({counts['keep_infect']/max(1,counts['infect_total']):.1%})\")\n",
    "print(f\"Non-infected stays : {counts['noninfect_total']}\")\n",
    "print(f\"  windows kept     : {counts['keep_noninfect']}  \"\n",
    "      f\"({counts['keep_noninfect']/max(1,counts['noninfect_total']):.1%})\")\n",
    "print(\"Rejections:\")\n",
    "for k in ('sparse','no_clean_lead','short_los'):\n",
    "    print(f\"  {k:<13}: {counts[k]}\")\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23610f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "# â”€â”€ file locations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# DATA_DIR    = r\"D:\\Users\\orosh\\Documents\\Research\\Datasets\\eicu-2.0\\processed\"\n",
    "DATA_DIR     = OUTPUT_PATH\n",
    "VITALS_CSV   = os.path.join(DATA_DIR, \"24h_windows\", \"vitals_24h_windows.csv.gz\")\n",
    "STATIC_CSV   = os.path.join(DATA_DIR, \"static_patient_info.csv.gz\")\n",
    "OUT_CSV      = os.path.join(DATA_DIR, \"balanced_24h_windows.csv.gz\")\n",
    "\n",
    "# â”€â”€ 1. load 24-h windows & infection-evidence tag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#   â€¢ use read_csv for .csv.gz\n",
    "#   â€¢ restrict dtypes to keep memory reasonable\n",
    "vitals_df = pd.read_csv(\n",
    "    VITALS_CSV,\n",
    "    dtype={\"stay_id\": \"int32\", \"infected\": \"int8\"},   # adjust as needed\n",
    "    low_memory=False\n",
    ")                                                    # 48Ã—N rows per stay\n",
    "\n",
    "static_df = pd.read_csv(\n",
    "    STATIC_CSV,\n",
    "    usecols=[\"stay_id\", \"infection_tag\"],\n",
    "    dtype={\"stay_id\": \"int32\", \"infection_tag\": \"int8\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a6dbdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in vitals: 3533568\n",
      "Number of unique stay_ids in vitals: 73616\n",
      "Number of infected patients: 10311\n",
      "Number of non-infected patients: 63305\n",
      "Number of infected patients with temp: 0\n",
      "Number of infected patients without temp: 21216\n",
      "Number of non-infected patients with temp: 0\n",
      "Number of non-infected patients without temp: 1920\n",
      "Number of rows with temp mean not nan: 324179\n",
      "Number of rows with temp mean not nan, grouped by stay_id:\n",
      "Number of stays with temp mean nan: 65619\n",
      "Number of stays with temp mean not nan 7997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>infection_tag</th>\n",
       "      <th>index</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>823.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>60973.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6650.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "infection_tag     index     1.0    2.0      2.5     3.0    4.0  5.0\n",
       "0              0.000000   823.0  327.0  60973.0   948.0    1.0  0.0\n",
       "1              0.020833  1941.0  912.0      0.0  6650.0  786.0  4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total infected stays in windows : 10311\n",
      "\n",
      "Saved balanced set â†’ D:\\Users\\orosh\\Documents\\Research\\Datasets\\eicu-2.0\\processed\\balanced_24h_windows.csv.gz\n",
      "\n",
      "Patients kept (rows = infected 0/1, columns = evidence tag):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>infection_tag</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_has_infection</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>823</td>\n",
       "      <td>327</td>\n",
       "      <td>9087</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1941</td>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>6650</td>\n",
       "      <td>786</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "infection_tag          1.0  2.0   2.5   3.0  4.0  5.0\n",
       "window_has_infection                                 \n",
       "0                      823  327  9087    50    0    0\n",
       "1                     1941  912     0  6650  786    4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vitals = vitals_df.copy()\n",
    "static = static_df.copy()\n",
    "\n",
    "#print how many rows in vitals and how many unique stay_ids that is\n",
    "#print how many in vitals are infected and how many are not\n",
    "print(\"Number of rows in vitals:\", len(vitals))\n",
    "print(\"Number of unique stay_ids in vitals:\", vitals[\"stay_id\"].nunique())\n",
    "#infected = at least one row with infected == 1 per stay_id\n",
    "infected = vitals.groupby(\"stay_id\")[\"infected\"].max()\n",
    "print(\"Number of infected patients:\", infected.sum())\n",
    "print(\"Number of non-infected patients:\", len(infected) - infected.sum())\n",
    "\n",
    "# return\n",
    "\n",
    "# â”€â”€ 2. mark windows that contain â‰¥1 infected bin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "has_inf = (vitals.groupby(\"stay_id\")[\"infected\"]\n",
    "                   .max()\n",
    "                   .rename(\"window_has_infection\")\n",
    "                   .reset_index())\n",
    "\n",
    "vitals = vitals.merge(has_inf, on=\"stay_id\", how=\"left\")\n",
    "vitals = vitals.merge(static,  on=\"stay_id\", how=\"left\")\n",
    "\n",
    "#make infected_tag 0 become 2.5 because we want to prioritize 1 and 2 first\n",
    "vitals[\"infection_tag\"] = vitals[\"infection_tag\"].replace(0, 2.5)\n",
    "\n",
    "#print how many infected has temp how many do not, how many not infected have temp and how many do not\n",
    "has_temp = (vitals.groupby(\"stay_id\")[\"temp_c_mean\"]\n",
    "                   .max()\n",
    "                     .rename(\"window_has_temp\")\n",
    "                     .reset_index())\n",
    "vitals = vitals.merge(has_temp, on=\"stay_id\", how=\"left\")\n",
    "\n",
    "temps_count = {}\n",
    "temps_count[\"infected_hastemp\"] = ((vitals[\"window_has_infection\"] == 1) & (vitals[\"window_has_temp\"] == 1)).sum()\n",
    "temps_count[\"infected_notemp\"] = ((vitals[\"window_has_infection\"] == 1) & (vitals[\"window_has_temp\"] == 0)).sum()\n",
    "temps_count[\"noninfected_hastemp\"] = ((vitals[\"window_has_infection\"] == 0) & (vitals[\"window_has_temp\"] == 1)).sum()\n",
    "temps_count[\"noninfected_notemp\"] = ((vitals[\"window_has_infection\"] == 0) & (vitals[\"window_has_temp\"] == 0)).sum()\n",
    "\n",
    "print(\"Number of infected patients with temp:\", temps_count[\"infected_hastemp\"])\n",
    "print(\"Number of infected patients without temp:\", temps_count[\"infected_notemp\"])\n",
    "print(\"Number of non-infected patients with temp:\", temps_count[\"noninfected_hastemp\"])\n",
    "print(\"Number of non-infected patients without temp:\", temps_count[\"noninfected_notemp\"])\n",
    "\n",
    "# count how many rows in the dataset have temp mean not nan\n",
    "print(\"Number of rows with temp mean not nan:\", vitals[\"temp_c_mean\"].notna().sum())\n",
    "\n",
    "temp_per_stay_id = {}\n",
    "#count how many rows in the dataset have temp mean not nan, grouped by stay_id\n",
    "for stay_id, group in vitals.groupby(\"stay_id\"):\n",
    "    # if the group has at least one row with temp mean not nan, add to the dict\n",
    "    if group[\"temp_c_mean\"].notna().any():\n",
    "        temp_per_stay_id[stay_id] = group[\"temp_c_mean\"].notna().sum()\n",
    "    else:\n",
    "        temp_per_stay_id[stay_id] = 0\n",
    "\n",
    "# print how many rows in the dataset have temp mean not nan, grouped by stay_id\n",
    "print(\"Number of rows with temp mean not nan, grouped by stay_id:\")\n",
    "\n",
    "#count how many are = 0 in the dict\n",
    "temp_count = 0\n",
    "for stay_id, count in temp_per_stay_id.items():\n",
    "    if count == 0:\n",
    "        temp_count += 1\n",
    "\n",
    "print(\"Number of stays with temp mean nan:\", temp_count)\n",
    "print(\"Number of stays with temp mean not nan\", len(temp_per_stay_id) - temp_count)\n",
    "\n",
    "# -- Print a table that shows the number of infected and non-infected patients grouped by stay id by infection tag\n",
    "# infected = 1, non-infected = 0\n",
    "# infection_tag = 0, 1, 2, 3, 4\n",
    "# one_per_stay = (vitals\n",
    "#                 .groupby([\"stay_id\", \"window_has_infection\", \"infection_tag\"])\n",
    "#                 .size()\n",
    "#                 .unstack(fill_value=0)\n",
    "#                 .rename_axis(index=None, columns=\"infection_tag\")\n",
    "#                 .reset_index()\n",
    "#                 )\n",
    "\n",
    "grouped = (vitals\n",
    "            .groupby([\"window_has_infection\", \"infection_tag\"])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "            .rename_axis(index=None, columns=\"infection_tag\")\n",
    "            .reset_index()\n",
    "            )\n",
    "grouped = grouped / 48\n",
    "display(grouped)\n",
    "\n",
    "# â”€â”€ 3. counts & target sample size â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_infected = has_inf[\"window_has_infection\"].sum()\n",
    "print(f\"Total infected stays in windows : {n_infected}\")\n",
    "\n",
    "# â”€â”€ 4. choose the same number of clean stays, prioritising temp coverage then low tag â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 4-a. count how many non-NaN temperature rows each stay has\n",
    "temp_counts = (vitals\n",
    "               .groupby(\"stay_id\")[\"temp_c_mean\"]\n",
    "               .apply(lambda s: s.notna().sum())\n",
    "               .rename(\"num_temp_rows\")\n",
    "               .reset_index())\n",
    "\n",
    "# 4-b. build the clean-stay pool, ordered by:\n",
    "#      1) most temperature measurements (descending)\n",
    "#      2) lowest infection_tag (ascending)\n",
    "clean_pool = (\n",
    "    vitals.query(\"window_has_infection == 0\")[[\"stay_id\", \"infection_tag\"]]\n",
    "          .drop_duplicates()\n",
    "          .merge(temp_counts, on=\"stay_id\", how=\"left\")\n",
    "          .sort_values([\"num_temp_rows\", \"infection_tag\"],\n",
    "                       ascending=[False, True])\n",
    ")\n",
    "\n",
    "# 4-c. take as many clean stays as there are infected ones\n",
    "chosen_clean_ids = clean_pool.head(int(n_infected))[\"stay_id\"]\n",
    "\n",
    "# (rest of the pipeline remains unchanged)\n",
    "infected_ids = vitals.query(\"window_has_infection == 1\")[\"stay_id\"].unique()\n",
    "final_ids    = np.concatenate([infected_ids, chosen_clean_ids])\n",
    "\n",
    "balanced = vitals[vitals[\"stay_id\"].isin(final_ids)].copy()\n",
    "\n",
    "# # â”€â”€ 4. choose the same number of clean stays, prioritising low tag â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# clean_pool = (\n",
    "#     vitals.query(\"window_has_infection == 0\")[[\"stay_id\", \"infection_tag\"]]\n",
    "#           .drop_duplicates()\n",
    "#           .sort_values(\"infection_tag\")            # best evidence (1) first\n",
    "# )\n",
    "\n",
    "# chosen_clean_ids = clean_pool.head(int(n_infected))[\"stay_id\"]\n",
    "\n",
    "# infected_ids = vitals.query(\"window_has_infection == 1\")[\"stay_id\"].unique()\n",
    "# final_ids    = np.concatenate([infected_ids, chosen_clean_ids])\n",
    "\n",
    "# balanced = vitals[vitals[\"stay_id\"].isin(final_ids)].copy()\n",
    "\n",
    "# â”€â”€ 5. save and report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "balanced.to_csv(OUT_CSV, index=False, compression=\"gzip\")\n",
    "\n",
    "summary = (balanced.drop_duplicates(\"stay_id\")\n",
    "                     .groupby([\"window_has_infection\", \"infection_tag\"])\n",
    "                     .size()\n",
    "                     .unstack(fill_value=0))\n",
    "\n",
    "print(f\"\\nSaved balanced set â†’ {OUT_CSV}\")\n",
    "print(\"\\nPatients kept (rows = infected 0/1, columns = evidence tag):\")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6a4d25c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random window of 10 rows from the balanced DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>offset_min</th>\n",
       "      <th>temp_c_mean</th>\n",
       "      <th>temp_c_std</th>\n",
       "      <th>temp_range30</th>\n",
       "      <th>temp_c_slope30h1</th>\n",
       "      <th>HR_bpm_mean</th>\n",
       "      <th>HR_bpm_std</th>\n",
       "      <th>HR_sdnn30</th>\n",
       "      <th>...</th>\n",
       "      <th>MAP_mmHg_std</th>\n",
       "      <th>MAP_slope30h1</th>\n",
       "      <th>spo2_pct_mean</th>\n",
       "      <th>spo2_pct_std</th>\n",
       "      <th>spo2_cv30</th>\n",
       "      <th>spo2_pct_min</th>\n",
       "      <th>infected</th>\n",
       "      <th>window_has_infection</th>\n",
       "      <th>infection_tag</th>\n",
       "      <th>window_has_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2034234</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 06:35:00</td>\n",
       "      <td>7595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.600000</td>\n",
       "      <td>3.286335</td>\n",
       "      <td>3.286335</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034235</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 07:05:00</td>\n",
       "      <td>7625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>8.358628</td>\n",
       "      <td>8.358628</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034236</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 07:35:00</td>\n",
       "      <td>7655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.333333</td>\n",
       "      <td>6.531973</td>\n",
       "      <td>6.531973</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034237</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 08:05:00</td>\n",
       "      <td>7685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.333333</td>\n",
       "      <td>12.484657</td>\n",
       "      <td>12.484657</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034238</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 08:35:00</td>\n",
       "      <td>7715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034239</th>\n",
       "      <td>1853966</td>\n",
       "      <td>5 days 09:05:00</td>\n",
       "      <td>7745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>2.422120</td>\n",
       "      <td>2.422120</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034240</th>\n",
       "      <td>1853981</td>\n",
       "      <td>0 days 02:32:00</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>1.366260</td>\n",
       "      <td>1.366260</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034241</th>\n",
       "      <td>1853981</td>\n",
       "      <td>0 days 03:02:00</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>0.752773</td>\n",
       "      <td>0.752773</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034242</th>\n",
       "      <td>1853981</td>\n",
       "      <td>0 days 03:32:00</td>\n",
       "      <td>212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.949684</td>\n",
       "      <td>3.949684</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034243</th>\n",
       "      <td>1853981</td>\n",
       "      <td>0 days 04:02:00</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>1.940790</td>\n",
       "      <td>1.940790</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stay_id               ts  offset_min  temp_c_mean  temp_c_std  \\\n",
       "2034234  1853966  5 days 06:35:00        7595          NaN         NaN   \n",
       "2034235  1853966  5 days 07:05:00        7625          NaN         NaN   \n",
       "2034236  1853966  5 days 07:35:00        7655          NaN         NaN   \n",
       "2034237  1853966  5 days 08:05:00        7685          NaN         NaN   \n",
       "2034238  1853966  5 days 08:35:00        7715          NaN         NaN   \n",
       "2034239  1853966  5 days 09:05:00        7745          NaN         NaN   \n",
       "2034240  1853981  0 days 02:32:00         152          NaN         NaN   \n",
       "2034241  1853981  0 days 03:02:00         182          NaN         NaN   \n",
       "2034242  1853981  0 days 03:32:00         212          NaN         NaN   \n",
       "2034243  1853981  0 days 04:02:00         242          NaN         NaN   \n",
       "\n",
       "         temp_range30  temp_c_slope30h1  HR_bpm_mean  HR_bpm_std  HR_sdnn30  \\\n",
       "2034234           NaN               NaN    79.600000    3.286335   3.286335   \n",
       "2034235           NaN               NaN    83.333333    8.358628   8.358628   \n",
       "2034236           NaN               NaN   103.333333    6.531973   6.531973   \n",
       "2034237           NaN               NaN   100.333333   12.484657  12.484657   \n",
       "2034238           NaN               NaN    86.000000    0.000000   0.000000   \n",
       "2034239           NaN               NaN    86.666667    2.422120   2.422120   \n",
       "2034240           NaN               NaN    86.333333    1.366260   1.366260   \n",
       "2034241           NaN               NaN    86.833333    0.752773   0.752773   \n",
       "2034242           NaN               NaN    90.000000    3.949684   3.949684   \n",
       "2034243           NaN               NaN    89.166667    1.940790   1.940790   \n",
       "\n",
       "         ...  MAP_mmHg_std  MAP_slope30h1  spo2_pct_mean  spo2_pct_std  \\\n",
       "2034234  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034235  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034236  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034237  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034238  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034239  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034240  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034241  ...           NaN            NaN     100.000000      0.000000   \n",
       "2034242  ...           NaN            NaN      99.833333      0.408248   \n",
       "2034243  ...           NaN            NaN     100.000000      0.000000   \n",
       "\n",
       "         spo2_cv30  spo2_pct_min  infected  window_has_infection  \\\n",
       "2034234   0.000000         100.0         1                     1   \n",
       "2034235   0.000000         100.0         1                     1   \n",
       "2034236   0.000000         100.0         1                     1   \n",
       "2034237   0.000000         100.0         1                     1   \n",
       "2034238   0.000000         100.0         1                     1   \n",
       "2034239   0.000000         100.0         1                     1   \n",
       "2034240   0.000000         100.0         0                     1   \n",
       "2034241   0.000000         100.0         0                     1   \n",
       "2034242   0.004089          99.0         0                     1   \n",
       "2034243   0.000000         100.0         0                     1   \n",
       "\n",
       "         infection_tag  window_has_temp  \n",
       "2034234            3.0              NaN  \n",
       "2034235            3.0              NaN  \n",
       "2034236            3.0              NaN  \n",
       "2034237            3.0              NaN  \n",
       "2034238            3.0              NaN  \n",
       "2034239            3.0              NaN  \n",
       "2034240            4.0              NaN  \n",
       "2034241            4.0              NaN  \n",
       "2034242            4.0              NaN  \n",
       "2034243            4.0              NaN  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a random window of 10 rows from the balanced DataFrame\n",
    "\n",
    "#pick a random pos\n",
    "random_window_start = np.random.randint(0, len(balanced)-10)\n",
    "random_window_end = random_window_start + 10\n",
    "\n",
    "random_window = balanced.iloc[random_window_start:random_window_end]\n",
    "print(\"Random window of 10 rows from the balanced DataFrame:\")\n",
    "random_window.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6b7bf810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in static_patient_info.csv.gz:\n",
      "['stay_id', 'gender', 'admit_dx', 'hosp_admit_source', 'unit_type', 'unit_admit_source', 'weight_kg', 'discharge_offset', 'age', 'infection_tag']\n",
      "Columns in balanced_24h_windows.csv.gz:\n",
      "['stay_id', 'ts', 'offset_min', 'temp_c_mean', 'temp_c_std', 'temp_range30', 'temp_c_slope30h1', 'HR_bpm_mean', 'HR_bpm_std', 'HR_sdnn30', 'HR_delta_prev', 'RR_bpm_mean', 'RR_bpm_std', 'RR_range30', 'MAP_mmHg_mean', 'MAP_mmHg_std', 'MAP_slope30h1', 'spo2_pct_mean', 'spo2_pct_std', 'spo2_cv30', 'spo2_pct_min', 'infected', 'window_has_infection', 'infection_tag', 'window_has_temp']\n"
     ]
    }
   ],
   "source": [
    "#print all cols names in static_patient_info.csv.gz and balanced_24h_windows.csv.gz\n",
    "static_cols = pd.read_csv(STATIC_CSV).columns.tolist()\n",
    "print(\"Columns in static_patient_info.csv.gz:\")\n",
    "print(static_cols)\n",
    "# print all cols names in balanced_24h_windows.csv.gz\n",
    "balanced_cols = pd.read_csv(OUT_CSV).columns.tolist()\n",
    "print(\"Columns in balanced_24h_windows.csv.gz:\")\n",
    "print(balanced_cols)\n",
    "\n",
    "# Columns in static_patient_info.csv.gz:\n",
    "# ['stay_id', 'gender', 'admit_dx', 'hosp_admit_source', 'unit_type', 'unit_admit_source', 'weight_kg', 'discharge_offset', 'age', 'infection_tag']\n",
    "# Columns in balanced_24h_windows.csv.gz:\n",
    "# ['stay_id', 'ts', 'offset_min', 'temp_c_mean', 'temp_c_std', 'temp_range30', 'temp_c_slope30h1', 'HR_bpm_mean', 'HR_bpm_std', 'HR_sdnn30', 'HR_delta_prev', 'RR_bpm_mean', 'RR_bpm_std', 'RR_range30', 'MAP_mmHg_mean', 'MAP_mmHg_std', 'MAP_slope30h1', 'spo2_pct_mean', 'spo2_pct_std', 'spo2_cv30', 'spo2_pct_min', 'infected', 'window_has_infection', 'infection_tag', 'window_has_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bd715b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random patient ID: 246400\n",
      "Number of rows for this patient: 48\n"
     ]
    }
   ],
   "source": [
    "#pick a random patient in vitals, say how many rows it has\n",
    "static = pd.read_csv(STATIC_CSV)\n",
    "vitals = pd.read_csv(OUT_CSV)\n",
    "random_patient = np.random.randint(0, len(vitals)-1)\n",
    "random_patient_id = vitals.iloc[random_patient][\"stay_id\"]\n",
    "random_patient_rows = vitals[vitals[\"stay_id\"] == random_patient_id]\n",
    "print(\"Random patient ID:\", random_patient_id)\n",
    "print(\"Number of rows for this patient:\", len(random_patient_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a35342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vitals dataset: (989856, 25)\n",
      "Shape of static dataset: (195339, 10)\n"
     ]
    }
   ],
   "source": [
    "#print shape of both dataset\n",
    "print(\"Shape of vitals dataset:\", vitals.shape)\n",
    "print(\"Shape of static dataset:\", static.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEWS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
